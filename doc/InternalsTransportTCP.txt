The TCP Transport
=================

Overview
--------

When a TCP transport is created a new server is started which listens on a
given port number on the local host. In order to support multiple connections
the transport maintains a set of channels, one per connection, represented as a
pair of a `MVar [ByteString]` and a list of pairs `(ThreadId, Socket)` of
threads that are listening on this channel. A source end then corresponds to a
hostname (the hostname used by clients to identity the local host), port
number, and channel ID; a receive end simply corresponds to a channel ID.

When `mkTransport` creates a new transport it spawns a thread that listens for
incoming connections, running `procConnections` (see below). The set of
channels (connections) associated with the transport is initialized to be
empty. 

`newConnectionWith` creates a new channel and add its to the transport channel
map (with an empty list of associated threads).

To serialize the source end we encode the triple of the local host name, port
number, and channel ID, and to deserialize we just decode the same triple
(deserialize does not need any other properties of the TCP transport).

To connect to the source end we create a new socket, connect to the server at
the IP address specified in the TCPConfig, and send the channel number over the
connection. Then to `closeSourceEnd` we simply close the socket, and to send a
bunch of byte strings we output them on the socket.

To receive from the target end we just read from the channel associated with
the target end. To `closeTargetEnd` we find kill all threads associated with
the channel and close their sockets.

When somebody connects to server (running `procConnections`), he first sends a
channel ID. `procConnections` then spawns a new thread running
`procMessages` which listens for bytestrings on the socket and output them on
the specified channel.  The ID of this new thread (and the socket it uses) are
added to the channel map of the transport.

`closeTransport` kills the server thread and all threads that were listening on
the channels associated with the transport, and closes all associated sockets.

Improving Latency
-----------------

A series of benchmarks has shown that

* The use of `-threaded` triples the latency.

* Prepending a header to messages has a negligible effect on latency, even when
  sending very small packets. However, the way that we turn the length from an
  `Int32` to a `ByteString` _does_ have a significant impact; in particular,
  using `Data.Serialize` is very slow (and using Blaze.ByteString not much
  better).  This is fast:

        foreign import ccall unsafe "htonl" htonl :: CInt -> CInt
        
        encodeLength :: Int32 -> IO ByteString
        encodeLength i32 =
          BSI.create 4 $ \p ->
            pokeByteOff p 0 (htonl (fromIntegral i32))

* We do not need to use `blaze-builder` or related; 
  `Network.Socket.Bytestring.sendMany` uses vectored I/O. On the client side
  doing a single `recv` to try and read the message header and message, rather
  one to read the header and one to read the payload improves latency, but only
  by a tiny amount. 

* Indirection through an `MVar` or a `Chan` does not have an observable effect
  on latency.  

* When two nodes _A_ and _B_ communicate, latency is worse when they
  communicate over two pairs of sockets (used unidirectionally) rather than one
  pair (used bidirectionally) by about 20%. This is not improved by using
  `TCP_NODELAY`, and might be because [acknowledgements cannot piggyback with
  payload][1] this way. It might thus be worthwhile to try and reuse TCP
  connections (or use UDP).

[1]: http://lists.freebsd.org/pipermail/freebsd-hackers/2009-March/028006.html "2 uni-directional TCP connection good?"
